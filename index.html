<!DOCTYPE HTML>

<html>
	<head>
		<title>Christian Lee Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="content">
							<div class="inner">
								<h1>Portfolio</h1>
								<p>Christian Lee</p>
								<P>This Portolio represents my body of work</P>
							</div>
						</div>
						<nav>
							<ul>
								<li><a href="#intro">Intro</a></li>
								<li><a href="#work">Projects</a></li>
								<li><a href="#about">About Me</a></li>
								
								<!--<li><a href="#elements">Elements</a></li>-->
							</ul>
						</nav>
					</header>

				<!-- Main -->
					<div id="main">

						<!-- Intro -->
							<article id="intro">
								<h2 class="major"></h2>
								<span class="image main"><img src="images/pic01.jpg" alt="" /></span>
								<p> I am currently in the Master in Data Science Program at UC Berkeley.
									As of now, the courses I am taking are Statistics for Data Science and Introduction to Data Engineering. Prior course I have completed are Introduction to Data Science Programming, Research Design and Applications. 
									I'm pursuing a career in Data Engineering and Machine Learning.</p>
								
								<p> I have gained a certification from completing a Python Bootcamp from Udemy, 
									SQL Mastery course through codewithmosh, and an Introduction to Analytics 2 course provided by NC State. 
									</p>
								<p> I have developed a scrabble word finder, a card game of war, black jack, and guess the number in python. 
									For my relevant work experience I have developed an automated dashboard viewable on SharePoint. 
									I connected the Dashboard to a SQL server and worked with the Quality Assurance SME on KPI/metrics displayed. 
									The dashboard was automated to update on a weekly frequency.</p>
								<P><a href="#work"> Click here to check out my projects</a>.
								<br> If you would like to contact me please reach out via email (celee@berkeley.edu).
								</P>

								
							</article>

						<!-- Work -->
							<article id="work">
								<h2 class="major">Projects</h2>
								<span class="image main"><img src="images/pic02.jpg" alt="" /></span>
								<p> Below are buttons that links to different highlighted projects I have worked on my own or my coursework at Berkeley.
									Each project goes into depth of the different analysis I or a team I collaborated with conducted. 
									Please check out any that interest you.</p>
								
								<button style ="margin:3px" type="button" onclick="location.href='#OOP'">OOP</button>
								<button style ="margin:3px" type="button" onclick="location.href='#EDA'"> EDA</button>
								<button style ="margin:3px" type="button" onclick="location.href='#PostSQL'">PostGRE SQL</button>
								<button style ="margin:3px" type="button" onclick="location.href='#DataW'">Data Wrangling</button>
								<button style ="margin:3px" type="button" onclick="location.href='#Stats'">Statistical Analysis</button>
								<button style ="margin:3px" type="button" onclick="location.href='#Causal'">Causal Modeling</button>		
								<button style ="margin:3px" type="button" onclick="location.href='#GraphD'">Graph Databases</button>
								<button style ="margin:3px" type="button" onclick="location.href='#Viz'">Interactive Dashboard</button>

								<P><br>My berkeley programming course material can be found within this <a href="https://github.com/ejunlee/Berkeley_MIDS/tree/main"> repo</a>.<br>
									The games I have developed in Python can be found within this<a href="https://github.com/ejunlee/Fun_Programs"> repo</a>.</P>
								
							</article>

						<!-- About -->
							<article id="about">
								<h2 class="major">About Me</h2>
								<span class="image main"><img src="images/Headshot_Photo.jpg" alt="" /></span>
								<p>Christian Lee (He/Him)</p>
								<p>I am pursing a Master's in Data Science at UC Berkeley in pursuit of becoming a Data Scientist in the Tech world. 
									Prior to becoming a full time student I was working as a Senior Analyst at CREO working on a plethora of different projects.
                                    At the consulting firm I help developed 30+ process maps to identify bottlenecks, pain points, and areas to invest in to drive operational improvements.
                                    Worked with SMEs to assess data governance practices, analytic platforms, data strategy, and data pipelines for cliental.
								</p>
								<p> 
								Prior to switching to the data world, I majored in Chemical Engineering at NC State. 
								I worked as a process/project engineer and ended my career as a project manager. 
								I have a lot of experience with good documentation practices, developing and executing engineering studies, and commissioning and qualification of new equipment.
								<br> Check out my Linkedin page for more work related information.
								</p>
								<ul class="icons">
									<li><a href="https://www.linkedin.com/in/christian-lee08/" class="icon brands fa-linkedin"><span class="label">linkedin</span></a></li>
									<li><a href="https://github.com/ejunlee" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
								</ul>
							</article>
						
							<!-- OOP -->
							<article id ="OOP">
								<button type="button" onclick="location.href='#work'"> Back to Project List</button>
								<br><br>
								<h2 class = "major">Building a Second-Price<br>Auction: OOP Competition</h2>
								<p>By: Christian Lee
								<br><a href = "https://github.com/ejunlee/Portfolio/tree/main/OOP">Click for the Github Repo</a>
								</p>

								<p>
								<u><strong>Introduction</strong></u>
								<br>
								You have been hired by a major retailer to develop algorithms for an online ad auction. Your client knows a little about the multi-armed bandit literature and recognizes that it can spend money to explore, learning how likely users are to click on ads, or to exploit, spending on the most promising users to maximize immediate payoffs. At the same time, there are other companies participating in the auction that may outbid your client, potentially interfering with these goals. Your task is to model the ad auction and develop an effective algorithm for bidding in a landscape of strategic competitors. Your client plans to test your bidding algorithm against other bidding algorithms contributed by other data scientists, in order to select the most promising algorithm.
								<br><br>
								<u><strong>The Auction Rules</strong></u>
								<br>
								The Auction has a set of bidders and users and multiple rounds representing an event which a user navigates to a website with a space for an ad. When this occurs the group of bidders will place to have an opportunity to show the select user their ad.  The user may click or not click the ad and the winning bidder gets to observe the users behavior. The rule is the same as a second price sealed-bid auction.
								<br><br>
								There are num_users User s, numbered from 0 to num_users - 1 . The number corresponding to a user will be called its user_id . Each user has a secret probability of clicking, whenever it is shown an ad. The probability is the same, no matter which Bidder gets to show the ad, and the probability never changes. The events of clicking on each ad are mutually independent. When a user is created, the secret probability is drawn from a uniform distribution from 0 to 1.
								<br><br>
								There is a set of Bidder s. Each Bidder begins with a balance of 0 dollars. The objective is to finish the game with as high a balance as possible. At some points during the game, the Bidder 's balance may become negative, and there is no penalty when this occurs.
								<br><br>
								The Auction occurs in rounds, and the total number of rounds is num_rounds. In each round, a second-price auction is conducted for a randomly chosen User. Each round proceeds as follows:
								<br>
								1. A User is chosen at random, with all User s having the same probability of being chosen. Note that a User may be chosen during more than one round. 
								<br>
								2. Each Bidder is told the user_id of the chosen User and gets to make a bid. The bid can be any non-negative amount of money in dollars. A Bidder does not get to know how much any other Bidder has bid. 
								<br>
								3. The winner of the auction is the Bidder with the highest bid. In the event that more than one Bidder ties for the highest bid, one of the highest Bidder’s is selected at random, each with equal probability. 
								<br>
								4. The winning price is the second-highest bid, meaning the maximum bid, after the winner's bid is removed, from the set of all bids. If the maximum bid was submitted by more than one bidder then the second price will be the maximum bid. For example, if two bidders bid 2 and no one else bids higher then 2 is the winning price. 
								<br>
								5. The User is shown an ad and clicks or doesn't click according to its secret probability. 
								<br>
								6. Each Bidder is notified about whether they won the round or not, and what the winning price is. Additionally, the winning Bidder (but no other Bidder) is notified about whether the User clicked.
								<br>
								7. The balance of the winning Bidder is increased by 1 dollar if the User clicked (0 dollars if the user did not click). It is also decreased by the winning price (whether or not the User clicked).
								<br><br>
								<u><strong>Sequence Diagram</strong></u>
								
								<center><br> 
								<span class="image fit">
								<img src="images/OOP/pic1.png" alt=""/></span>
								</center>
								<u>Game Setup</u>
								<br>
								1.	Create Users.
								<br>
								2.	Create Bidders.
								<br>
								3.	Designate number of rounds.
								<br>
								4.	Create Auction object with user and bidder list passed in.
								<br>
								<u>Running the simulation</u>
								<br>
								5.	Auction class will be called and will randomly choose a user.
								<br>
								6.	The auction asks if the bidders would like to bid for a specific user.
								<br>
								7.	Bidders have the option to bid knowing who the user is.
								<br>
								8.	The highest bidder is selected but only gets charged the second highest bid amount. If a tie occurs, then a bidder is randomly chosen out of the two and the tied bid will be the charged bid cost.
								<br>
								9.	The ad is shown to the user and the user will randomly choose to watch the ad. Each user has a different probability whether to watch or not.
								<br>
								10.	The user sends information to the auction whether the ad was watched, and the auction notifies the winning bidder if the user watches or not.
								<br>
								11.	If the user watched, then the bidder is rewarded a dollar.
								<br>
								12.	The auction holds the balance of each bidder and updates the accounting books (a dictionary object).
								<br>
								13.	Another round will be played until the auction has reached the set number of rounds played.
								<br><br>
								<u><strong>Deep Dive into the Architecture and Code</strong></u>
								<br>
								<strong>Architecture for each user:</strong>
								<br>
								The code below is the user class. Each user object has a random probability designated. The show_ad function in the user class is binary choice to watch or not watch the ad and will return the results to the Auction. The show_ad function is called in the auction class.								<br>
								<center>
								<span class="image fit">
								<img src="images/OOP/user1.PNG" alt=""/>
								</span>
								</center>
								
								<strong>Architecture for the bidders:</strong>
								<br>
								In this section I will go through the architecture of the bidder class at a high level. There are comments in the code to explain each portion of the code.
								<br>
								The class Bidder can pass in two parameters, the number of users in the auction and the number of rounds the auction will conduct. Each bidder object will have an idea of the number of users, number of rounds, a dictionary of the users (key is the users and values are the number of times the bidder has won a bid for that user), a personal winnings list, a counter to count the number of bids made, and user dictionary to see how many times a user has watched an ad. The bid function will be called during the auction class. The bid can take in the user parameter. The idea for this code is collect information of the user and make a strategic bid. The way I designed this algorithm is to find that user from the bidders users list and take the ratio of times the user has watched over the times the bidder has paid to show the user an ad. For the first hundred rounds the bidder bids a dollar, not exceeding the winnings cost, to collect information and stop other bidders from knowing the users. By taking each users information early on, I am able to learn about the user and learn the probability of the user clicking the ad or not. Having this information early on I can bid aggressive for the users with high probability. The code has room for improvement to better designate the probability requirement for how willing a bidder will pay. Under the stringent time frame when the code was developed, this was gauged with a couple of simulations. If time was allowed, I would have run over a hundred simulations of the different bidder models and run a regression on probability amount and bis amount to find the highest return. 								<center>
								<span class="image fit">
								<img src="images/OOP/bid1.PNG" alt=""/>
								</span>
								</center>
								The notify function within the bidder’s class is to notify the bidder if the user has watched the ad or not. This function is executed in the auction class. This portion of the code is where the bidder collects information on the user’s activity and learns more about the users actions.
								<center>
								<span class="image fit">
								<img src="images/OOP/bid2.PNG" alt=""/>
								</span>
								</center>
								Please note that one bidder was created and tested and competed with other bidder classes created by other students. There was a competition within the programming class to see whose bidder would have the highest return. My bidder and the bidding strategy was in the 90th percentile.
								<br><br>

								<strong>Architecture for the Auction:</strong>
								<br>
								The Auction class takes in the users list and bidders list. The auction creates a dictionary of the bidders and stores information on the bidders’ balance.
								<center>
								<span class="image fit">
								<img src="images/OOP/auction1.PNG" alt=""/>
								</span>
								</center>

								The two code snippets below are both snippets of the execute_round function. The execute_round function within the Auction class is to simulate an event/round of the auctioning. First a user is randomly selected, and the bidders’ bid function is called for each bidder. The bidders are told which user was chosen to potentially click their ad and the bid function is called to see whether a bidder wants to bid on that viewer. Afterwards the auction finds the highest bidder by using the max function to parse through the bidders list. Now the auction object needs to find the second highest bidder and that is done by sorting through the bidder dictionary values and choosing the second highest. Then the auction checks to see if the first highest bidder had bid more than the second highest bidder. If the bids are not equal, then the winner is the highest bidder, and the highest bidders pays the cost that is equivalent to the second highest bidders bid. If bids are equal than the bidder is randomly chosen from the two. After the highest bidder has paid the second highest bid price, the user is shown the ad and decides to click it or not. If the ad has been viewed than the balance of the highest bidder has increased by 1 dollar. The other bidders are notified that the bidder has won the bid but not if the viewer has clicked the ad or not. The highest bidder is notified if the viewer had clicked the ad or not.
								<center>
								<span class="image fit">
								<img src="images/OOP/auction2.PNG" alt=""/>
								<img src="images/OOP/auction3.PNG" alt=""/>
								</span>
								</center>

								<u><strong>Running the code</strong></u>
								<br>
								If you would like to run my code you can open the Test_py_files.ipynb jupytr notebook and run the code seen below. At the top of the page is my github folder for the program and where you can access the code.  You will need to have the numpy library in order to run the code. The numpy library was used for the “random” functions.								<center><br> 
								<center>
								<span class="image fit">
								<img src="images/OOP/pic2.png" alt=""/>
								<img src="images/OOP/pic3.png" alt=""/>
								</span>
								</center>
								</p>

							</article>

							<!-- EDA -->
								<article id="EDA">
								<button type="button" onclick="location.href='#work'"> Back to Project List</button>
								<h2></h2>
								
								<h2 class="major">Global CO2 Emissions <br>
									1980 to 2019		
												
								</h2>
								<p>
									<small>By: Christian Lee, Hardeep Sangha, Jose DelValle</small>
									<br><a href = "https://github.com/ejunlee/Global-CO2-Emissions-1980-to-2019/tree/main">Click for the Github Repo</a>
								</p>
									
									<u>Overview</u>
									<br>Climate change can negatively impact the world by producing severe droughts, rise in sea levels, and extreme weather conditions resulting in natural disasters on a scale never seen before. Climate change is the accumulation of greenhouse gasses resulting in long-term change in global temperature and weather patterns. There are many natural reasons for greenhouse gasses to be emitted, but a significant portion of emissions are generated by humans. Greenhouse gasses are comprised of 7 types of gasses and the greenhouse gas that is largely generated due to the human factor* is Carbon Dioxide (CO2).  

									In this project we will be exploring multiple aspects and uncovering insights with CO2 emission with population growth and income groups, countries energy production and consumption, and clean energy production.
									<br>
									<br>
									<u>By exploring the datasets of CO2 levels, we intend to discover:</u>  
									<br>1. What is the direct impact of population growth w/o accounting for energy type to CO2?
									<br>2. What trends are we seeing in the adoption of different energy types across countries? Are these trends different based on the country's income group - low, medium, high?
									<br>a. How does the energy trend look in the world regions?
									<br>b. What is the trend for the death rate per 100K population based on air pollution, and is there any relationship to CO2 emission?
									<br>3. What is the world’s trend on renewable energy production?
									<br>4. Which large country had the greatest percent decrease in CO2 emissions from their peak?
								</p>
								
								<p>
									<u>Data Preperation</u><br>
									When we initially started this project, we tried to find a main dataset that was already in good condition. There were several other topics we thought of doing but their datasets were far too messy. Because of this, there wasn’t too much that we needed to do to get our data ready for analyzing. Most of our files came in completely fine but there was one (Supplemental Dataset 1) that had 4 extra rows on the top for the title and date. Python would get an error when trying to import the data, so we had to manually delete the top 4 rows. 
									<br><br>
									After this we were able to import all the datasets with no problem. Once we stored the data as dataframes the next step was to get rid of any columns that didn’t have any information a.k.a. NaN values. We did this to all four of our dataframes and moved on to renaming the columns to something that was easier to use. We renamed any similar columns to have the exact same name, for example “Country Name” would be renamed to “Country” because it’s shorter, easier to work with (spaces make referring to a column difficult), and it made all the datasets match. Next, we needed to make all the dataframes have only 1 year column. Supplemental Dataset 1 had columns for every year, so we melted that dataframe to match the others.
									<br><br>
									We needed to be able to work with the numeric values of our data, so we converted all numeric values into numeric types. This way we could use aggregation functions on them like sum(), max(), and mean(). After this we wanted to combine several of our dataframes together to create one big final dataframe that we could all use to start with. In order to do this, Supplemental Dataframe 2 needed to have a column of “Energy_type” with the value of “all_energy_types”. Then we merged Supplemental Dataframe 2 with Supplemental Dataframe 1 to create a combined supplemental dataframe. Finally, we merged our Main Dataframe with the combined supplemental dataframe and created the final dataframe. In the end, our final dataframe contains 55,440 rows and 14 columns. It has information from 1980 to 2019 and contains information on 230 countries. 
									<br><br>
									Supplemental Dataframe 3 was added so we could ask even more questions about the impact of CO2 on deaths. We decided to create another version of the final dataframe because we already had invested a lot of time into the project and didn’t want to change the original final dataframe. We also added Supplemental Dataframe 4 that included all the countries and their country codes because the main dataset didn’t include every country. This dataframe was added to create a time series choropleth map.
								</p>
								<p>
									<b>What is the direct impact of population growth w/o accounting for energy type to CO2?</b>
									<br>We have observed no direct relationship between population growth experienced by a country and its CO2 emission levels. It is observed that industrialized nations tend to produce higher levels of CO2 compared to countries with similar population growth but much less industrialization and manufacturing capabilities.
									
									<center>
									<span class="image fit"><img src="images/EDA/fig1.png" alt=""/>
									<figcaption>Figure 1: Top 10 countries with highest total CO2 emissions</figcaption>
									</span>
									</center>
									
									Figure 1 showing the total C02 emission by top 10 countries. At the start of the research, we were assuming China, and India to be the top two producers. Our analysis showed that the USA has emitted the highest total CO2 for the period recorded in this study (1980 – 2019) closely followed by China.
									
									<center>
									<br> 
									<span class="image fit">
									<img src="images/EDA/fig2.png" alt=""/>
									<figcaption>Figure 2: CO2 emission, and population growth trend for USA, and China</figcaption>
									</span>
									</center>
									
									Figure 2 above shows detailed CO2 emissions by China, and the US over the research period. Both countries show a growth in population trend, the US over the last decade has made efforts to reduce the CO2 emission, although more recently it has started trending upwards again. China made some effort to reduce CO2 emission in the last decade as well but is trending upward again and is the top CO2 emitter for the current decade.
									
									<center>
									<br> 
									<span class="image fit"><img src="images/EDA/fig3.png" alt=""/> 
									<figcaption>Figure 3: CO2 emission, and population growth trend for Russia, and Japan</figcaption>
									</span>
									</center>

									Figure 3 demonstrates another view to illustrate that although both Japan, and Russia experienced a downward trend in population growth, the CO2 emission didn’t follow the same trend.
									<br><br>
									<b>What trends are we seeing in the adoption of different energy types across countries? Are these trends different based on the country's income group - low, medium, high?</b>
									
									<center><br> 
									<span class="image fit"><img src="images/EDA/fig4.png" alt=""/> <figcaption>Figure 4: CO2 emission by energy type and income group</figcaption></span>
									<span class="image fit"><img src="images/EDA/tab1.png" alt=""/> <figcaption>Table 1: Listing the low CO2 emission for low income countries</figcaption></span>
									</center>
									
									Note for the data above nuclear and renewables_n_other have no direct CO2 emission and are listed as Zero. Following observations can be made from Figure 4, and Table 1 about the question of adoption of different energy types across countries based on different income group:
									<br>•	Low-income countries' contribution to the overall C02 emission is the lowest.
									<br>•	Low-income countries primarily rely on petroleum-based energy types.
									<br>•	CO2 emission is directly related to the GDP of the income group, higher income group countries are responsible for higher CO2 emission rates.
									<br>•	Coal based energy type is the highest contributor for Upper middle-income countries
									<br>•	Petroleum based energy type is the highest contributor for High income countries
									<br>•	For both Lower middle income, and Upper middle income countries CO2 emission based on natural gas is similar.
									<br><br>
									<b>How does the energy trend look in world regions?</b>
									<br>Note on the dataset – the dataset and the supplement dataset used does not categorize all world countries by ‘Region’ designation, therefore the data analysis and visualization for this sub-question represent a trend of 130 countries as shown in the Table 2.
									
									<center>
									<br>
									<span class="image fit">
									<img src="images/EDA/tab2.png" alt=""/>
									<figcaption>Table 2: Population, Number of countries, and CO2 emission by region</figcaption>
									</span> 
									</center>
									
									It is noticeable that both Former U.S.S.R. and Russia did not have the ‘Region’ designation and are not included in the trend report. The North American region contains the United States, and Canada. 
									From Table 2 the clear trend is that most of the CO2 emission currently is happening from the East Asia and Pacific region that includes China which is the global manufacturing hub.
									<br><br>
									In the future if additional data becomes available for the past three years (2020-2022) that’ll be an interesting observation for the impact of the sars-cov-2 pandemic and how various global and regional shutdowns impacted the CO2 emission rates.
									
									<center>
									<br> 
									<span class="image fit">
									<img src="images/EDA/fig5.png" alt=""/>
									<figcaption>Figure 5: Trend report by region for CO2 emissions, number of countries, and population</figcaption>
									</span>
									</center>
									
									Figure 5 shows the CO2 emissions by region and total number of countries, and population contributing to the trend. Table 2 dataset is used to build out Figure 5.
									<br><br>
									<b>What is the trend for the death rate per 100K population based on air pollution?</b>
										Figure 5 shows the CO2 emissions by region and total number of countries, and population contributing to the trend. Table 2 dataset is used to build out Figure 5.
									<br>Note: There is a detailed heat map showing the trend in the death rate for each country in the jupyter notebook, for the sake of brevity, only top 20 countries with the highest death rate for the year 2019 are included in this report, Figure 6 below shows that using bar plot.
									<br><br>
									We did additional analysis on the death rate per 100K based on air pollution and noticed that the CO2 emission for Solomon Islands is one of the lowest on record. In order to ensure that the death rate per 100K was in fact this high for Solomon Islands we did literature research (Health Impacts of Climate Change in the Solomon Islands: An Assessment and Adaptation Action Plan: Jeffery T Spickett, and Dianne Katscherian 2014 Jun 24.) and uncovered that the death rate due to air pollution in Solomon Islands is a concern and health intervention is needed to increase understanding of the possible links between climate change, air quality, and health. 
									
									<center> 
									<br>
									<span class="image fit">
									<img src="images/EDA/fig6.png" alt=""/>
									<figcaption>Figure 6: Top 20 countries by death rate per 100K due to air pollution, and corresponding CO2 emission for the year 2019</figcaption>
									</span> 
									</center>
									
									In conclusion we observe no relationship between the CO2 emission and death rate per 100K based on air pollution as plotted in Figure 6.
									<br><br>

									<b>What is the world’s trend on renewable energy?</b>
									<br>We were interested to see if the world is taking climate change seriously and how has the world responded to the topic by generating renewable energy. By creating three different data frames we can plot, seen in Figure 7, the energy trend for renewable energy, nuclear energy, and the combination nuclear and renewable energy production per year.
									
									<center>
									<br> 
									<span class="image fit">
									<img src="images/EDA/fig7.png" alt=""/> 
									<figcaption>Figure 7: The world’s clean energy production is increasing every year.</figcaption>
									</span>
									</center>
									
									The renewable energy production has slowly increased until 2003 where it has increased at a higher rate than ever seen before. Nuclear energy had a large increase in the 1980 to 1985 and stopped increasing as much when renewable energy started to pick up. From 2004 to 2019 there has been a rise of renewable energy and a decrease in nuclear energy. The overall trend for the world is an increase in renewable energy and nuclear energy. We have defined clean energy as the summation of nuclear and renewable energy.
									
									<center>
									<br> 
									<span class="image fit">
									<img src="images/EDA/fig8.png" alt=""/> 
									<figcaption>Figure 8: China produces the most clean energy.</figcaption>
									</span>
									</center>
									
									The top 10 countries producing clean energy can be seen in Figure 8. China has produced the most renewable energy in 2019 while the US produces the most Nuclear Energy in 2019.  Overall, China produces the most clean energy. The countries in Figure 8 are countries that are in the top 15 highest GDP rankings based on Investopedia[1].
									<br><br>
									<b>Which large country had the greatest percent decrease in CO2 emissions from their peak?</b>
									<br>
									The first step was finding out when a country peaked in CO2 emissions. Once we found out which year was each country’s peak, we looked at any time after that for the lowest CO2 emission year. Then we subtracted the low from the peak to find the total decrease in CO2 emissions. We turned that into a percentage to find out which country had the largest percentage drop from their peak. The results weren’t very informative.
																	
									<center>
									<br> 
									<span class="image fit">
									<img src="images/EDA/tab4.png" alt=""/> 
									<figcaption>Table 4: Largest percent decrease of all countries</figcaption> 
									</span>
									</center>
									
									As you can see, our top country was Antarctica and then the U.S. Virgin Islands. Those countries are so small that any small change could cause huge swings in their CO2 levels. This made us update our question to include “large country” and “percent decrease” to avoid ambiguity of what we meant by the word decrease. So, we decided to look at the top 10 countries with the highest total drop in CO2 levels and then sort those by who had the highest percentage drop in CO2 levels. When we did that, we got a much better list. 
									
									<center>
									<br> 
									<span class="image fit">
									<img src="images/EDA/tab5.png" alt=""/>
									<figcaption>Table 5: Better table that shows largest percent decrease of largest CO2 producing Countries</figcaption> 
									</span> 
									</center>

									This clearly showed us that Ukraine had the highest percentage drop of all the large countries. Next, we wondered what Ukraine could be doing to achieve the impressive 67% drop in CO2 emissions. We hypothesized that they most likely just stopped producing energy with coal and petroleum and switched over to nuclear or other renewable sources. To test this hypothesis, we had to plot the country’s energy type and production. This allowed us to quickly visualize the trend of all the energy types. What we found confused us. 
									
									<center>
									<br> 
									<span class="image fit">
									<img src="images/EDA/fig9.png" alt=""/>
									<figcaption>Figure 9: Shows Ukraine’s energy production by type, CO2 levels, and Population per year.</figcaption>
									</span>
									</center>

									It looks like Ukraine reduced CO2 levels by reducing the amount of coal production. It's interesting that they didn't increase production in any other forms of energy to compensate for the reduced energy. This made us question what else could be going on. Why wouldn’t Ukraine increase its output to compensate for all the coal energy production loss? We decided to add in Ukraine’s population just to see what it would look like. In question 1 we found out that Japan had a declining population and there wasn’t a correlation with CO2 levels. In that case, Japan’s population had dropped very little, around 2%, and it was a recent development. Whereas in Ukraine’s case, they had a massive 20% decline in population since 1993. Although this probably isn’t the only reason for the drastic decline in CO2 levels, it is most likely a heavy contributor. 
									</p>
									<p>
										<u>Conclusion</u> 
										<br>
										After cleaning and exploring the dataset, we have found multiple insights into the different factors affecting CO2 emission. To our surprise there is not a direct relationship between population growth experienced by a country and its CO2 emission levels. It does appear that more industrialized nations emit higher levels of CO2. Looking at the wealth of a nation and its emission of CO2, low-income countries emit the least amount of CO2 compared to other medium and higher income countries. Petroleum based energy has emitted the most CO2 compared to the other energy sources. There are countries that produce more energy than they consume, and the top 3 countries are Russia, Saudi Arabia, and Norway. The accumulation of the excess energy from 1980 to 2019 by the three countries is 1400 Quad BTU. This World in 1980 produced 292 Quad BTU of energy. There can be better planning for the three countries' energy production. The world has taken an initiative in reducing CO2 emissions and has increased the energy production of renewable energy. From 1980 to 2019 there has been a 300% increase in renewable energy production, and this has been a linear increase. 


									</p>

								</article>
							
							<!-- PostgreSQL -->
							<article id ="PostSQL">
								<button type="button" onclick="location.href='#work'"> Back to Project List</button>
								<br><br>
								<h2 class = "major">PostGRE SQL & Python for fast<br>Exploration and Vizualization</h2>
								<p>By: Christian Lee
								<br><a href = "https://github.com/ejunlee/Portfolio/tree/main/postgre_sql">Click for the Github Repo</a>
								</p>
								<p>
									<u><strong>Introduction</strong></u>
									<br>
									This projects setting was a data engineer working with data scientists and business leaders to pull SQL queries to make better informed decisions with data. This report will review the set up of the notebook and some code is excluded for personal proprietary reasons. The goal is to show different type of basic and advance queries.
									<br><br>
									<u><strong>Set up</strong></u>
									<br>
									The four libraries used are math, numpy, pandas and pscopg2. The numpy and pandas package will be used to read the SQL query and put the table into a dataframe. The psycopg2 library will connect to a database via host and port number with a username and password.
									<center>
									<span class="image fit">
									<img src="images/postgre_sql/set1.PNG" alt=""/>
									<img src="images/postgre_sql/set2.PNG" alt=""/>
									</span>
									</center>

									<u><strong>ERD</strong></u>
									<br>
									The primary goal of the Entity Relationship Diagram (ERD) is to show the tables relationship. Each box is a table with the table name written above the box. If any foreign key is part of the primary key, we use rounded corners on the box. Inside each box is a list of columns in the table. Columns that are part of the primary key are above the line and also have (PK) after them. Columns that are foreign keys have (FK) after them. When joining, join the foreign key to the primary key in the parent table. Relationships between tables are denoted using the crow's foot notation. The line touches the parent table. The crow's foot touches the child table. Dangerous joins are joins between tables not based on matching a foreign key to a primary key. They are often necessary, but be careful, as they can cause the "extra rows" problem or the "missing rows" problem. When loading data, parent rows must be loaded prior to child rows, otherwise the database will generate a foreign key violation error. When deleting data, child rows must be deleted before parent rows can be deleted, otherwise the database will generate a foreign key violation error.
									<center>
									<span class="image fit">
									<img src="images/postgre_sql/ERD1.PNG" alt=""/>
									<img src="images/postgre_sql/ERD2.PNG" alt=""/>
									</span>
									</center>

									<u><strong>Data Dictionary</strong></u>
									<br><a href = "https://github.com/ejunlee/Portfolio/blob/main/postgre_sql/data_dictionary">The data dictionary can be found on this page. (Click Here)</a>
									<br><br>

									<u><strong>Writing different queries to accomplish different business objectives</strong></u>
									<br>
									In this portion I will show different types of techniques to pull different information. The setup of each example is to discuss the business goal or obejctive, discuss key clauses or statements of each query, include a picture of each query, and the picture of each result. Clauses or statements in prior examples will not be discussed in later examples to reduce redudant information. I will note that example 10 is more of an advance example which will include all the other examples caluses and statements. I will put a focus more on the logic and structure of the code. Examples 1-9 will show how to use different sql clauses or statements to accomplish more generic requests.
									<br><br>
									<u>Example 1</u>
									<br>
									The goal in this query is to better understand the sales made by company and find the average spent per sale. In this query we used single functions to sum the total sales, count all the number of sales, and divide the total sales by the count of sales to find the average spent on a sale.
									<center>
									<span class="image fit"><img src="images/postgre_sql/ex1.1.png" alt=""/>
									</span>
									</center>

									<u>Example 2</u>
									<br>
									The objective for the query below is aggregate the data to different stores and take the total dollar made on sales, the count of transactions made, and the average spent on each transaction. In order to make this possible there has to be an inner or left outer join on the sales table to the store id. I chose to use an left outer join for to show order importance since an inner join’s order does not matter. The join is on a the store_id which is the primary key for both the sales and stores table (please refer to the ERD above). To aggregate the stores to apply different numerical manipulation you will need to apply the group function. At the end I apply and order by function to sort the data in ascending order by stores city name.									
									<center>
									<span class="image fit">
									<img src="images/postgre_sql/ex2.1.png" alt=""/>
									<img src="images/postgre_sql/ex2.2.png" alt=""/>
									</span>
									</center>

									<u>Example 3</u>
									<br>
									The goal of the query below is to query the same information as example 1 and 2 but instead aggregating by the month. In order to accomplish this query, you will need to first extract the month number from the sale_date which is scalar subquery. After extracting the month number, you can use the to_char function to tie each month number to its represented month. By grouping by the month number and month you can aggregate the data into each month and apply different mathematical functions.
									<center>
									<span class="image fit">
									<img src="images/postgre_sql/ex3.1.png" alt=""/>
									<img src="images/postgre_sql/ex3.2.png" alt=""/>
									</span>
									</center>

									<u>Example 4</u>
									<br>
									The goal for this query is to view sales data for each store at different months. In this example we add another complexity by combining what we accomplished in example 2 and 3. By extracting the month number from the sales table, doing an inner join with the sales and stores table on the store _id, and grouping by the object variables then can you accomplish the examples goal. Please refer to example 2 and 3 for a more depth look at the join and grouping.
									<center>
									<span class="image fit">
									<img src="images/postgre_sql/ex4.1.png" alt=""/>
									<img src="images/postgre_sql/ex4.2.png" alt=""/>
									</span>
									</center>

									<u>Example 5</u>
									<br>
									The goal for this query is the same as example 3, however you want to know the sales by week. The code is very similar to example 4 and so my explanation for this example will be more focused on the difference. In example 5 the extract function is taking the day of week from the sale_date record for that specific row. The days name will be identified by using the to_char function.
									<center>
									<span class="image fit">
									<img src="images/postgre_sql/ex5.1.png" alt=""/>
									<img src="images/postgre_sql/ex5.2.png" alt=""/>
									</span>
									</center>
									
									<u>Example 6</u>
									<br>
									The objective for the query is to aggregate the data by store name and day of the week in order to perform some mathematical functions. This example is a combination of example 4 and 5. The key difference between this example and 5 performing a join function between the stores and sales table on the primary key, store_id. By adding a new character column you will need to include that in the grouping function.
									<center>
									<span class="image fit">
									<img src="images/postgre_sql/ex6.1.png" alt=""/>
									<img src="images/postgre_sql/ex6.2.png" alt=""/>
									</span>
									</center>

									<u>Example 7</u>
									<br>
									The goal of this example is to find the customers who have signed up for the stores subscription, however have not purchased any goods.  Here we have a query to select the last and first name of the customer from the customer table. We want to filter out the customers who haven’t purchased anything by using a where clause and a scalar subquery. By using the customer_id from customers table that are not in the sales table we can accomplish the goal. 
									<center>
									<span class="image fit">
									<img src="images/postgre_sql/ex7.1.png" alt=""/>
									<img src="images/postgre_sql/ex7.2.PNG" alt=""/>
									</span>
									</center>

									<u>Example 8</u>
									<br>
									The goal of the query is to better understand the demographics of the customer by analyzing the percentage of customers in varying areas (zip codes). In order to accomplish this goad we will have to do a subquery with a with clause. We start by choosing our columns by selecting the zip code and the customer population percentage of each column. The customer population percentage is the total count of customers we have divided by the total population in the zip code from another table. I chose to use the zip code table as my main table and did a dangerous join with the customer table on the zip variable. The zip variable is a unique identifier and is a valid justification for the dangerous join (non-primary and foreign key joins). I used the with clause to count the number of customers we have in each zip code from the customers’ table. 
									<center>
									<span class="image fit">
									<img src="images/postgre_sql/ex8.1.png" alt=""/>
									<img src="images/postgre_sql/ex8.2.PNG" alt=""/>
									</span>
									</center>

									<u>Example 9</u>
									<br>
									The goal of the objective is to see how many meals were purchased by store and by meal. In order to accomplish this goal, we need to do multiple joins with multiple tables. I utilized the table that contained the information I wanted in order to do join with other tables to accumulate more details on each data point. I used the line_items table to join the stores table on the store_id to get information on the store and the product table on the product_id to gather the description on each product.
									<center>
									<span class="image fit">
									<img src="images/postgre_sql/ex9.1.png" alt=""/>
									<img src="images/postgre_sql/ex9.2.png" alt=""/>
									</span>
									</center>

									<u>Example 10</u>
									<br>
									For this example, I will put an emphasis on the logic of the code and how it was put together rather than explain the different SQL clauses and statements used. The goal of this example is to find the holiday days (including 7 days prior and after that holiday) where the actual sales differ by more than 15% from their expected sale for that day of the week. 
									<br><br>
									In order to accommodate this request by using one query, you will have to rely on several subqueries along with the main query. This is done by using the with clause and 5 subqueries within the main query. Taking this modular approach helps with aggregating different groups and then combining the data into a single desired data frame. The first subquery needed is creating a holidays table from the internal SQL table called holiday and, in my code, denoted as e. This subquery will be the foundation for identifying all the holiday data for that year. The second subquery needed is creating all the days of the year and this can be done using the generate series table. This query will assist the connection to the holidays date and the date within that calendar year.
									<br><br>
									The third subquery created will identify all general days of the week in a year and group them for that specific day of the week. This can be done using the generate series table (an internal SQL function) and the group by function. This subquery is within the with clause, and in my code is denoted as c. The importance of this function is to find the number of Monday, Tuesday, etc within a year. This table will be used as the denominator to find the actual sales dollars and expected sales dollars.
									<br><br>
									The fourth subquery will be the total sales made for each day by aggregating the sums for each specific day of the week and denoted as a. The coalesce function is introduced to handle the nans. Doing an EDA prior to this study, I found that the nans are days the store is closed like Christmas day. The fifth subquery needed is finding the expected sales of each general day of the week. This is done by aggregating the sum of the sales for each general day of the week. For example, each general day of the week could be Monday, Tuesday, etc and there will be 7 total rows for this table.
									<br><br>
									Finally, were close to the finish line and we need to combine all the subqueries to make the table we desire. We first want to use our date analyzed table as the main table in the query and this is because this will list all the days of the year. We will have four join clauses for each of the subqueries and use table d as the frame of reference. 
									<br><br>
									The first subquery is joining the day of the week (table c) for each day of the year (table d) on the day of the year key. Next, we will join the each day of the year table (table d) with the actual sales (table a) of that day on the sale date key. We will join the each day of the year table (table d) with the expected sales for that day table (table b) on the day of the week key. The next join will be a tricky join where you do a join with the holidays table (table e) with each day of the year table (table d). The join uses a between clause with a numerical function to include the 7 days before the holiday date and 7 days after the holiday date using the date of the year key. This will connect the holiday with the days of the holiday week. Now we can apply some mathematical function to get the actual sales data, expected sales data, and ratio of the actual and expected. This is done by grouping the holiday name, data analyzed, and day of the week. The actual sales dollars are the total sales made that day divided by the count of the general day of the week. The expected sales are the total sales for the general day of the week by the count of the general day of the week. The ratio is the actual sales dollars divided by expected sales dollar. The last thing to do is filter the dates to see where the store underperformed in sales by more than 15%. By using the where clause and setting the ratio of the actual and expected to be less than 85% you can code this desired table.
									<br>
									<center>
									<span class="image fit">
									<img src="images/postgre_sql/ex10.2.png" alt=""/>
									<img src="images/postgre_sql/ex10.3.png" alt=""/>
									<img src="images/postgre_sql/ex10.4.png" alt=""/>
									</span>
									</center>

									<u><strong>Analysis and Data Visualization</strong></u>
									<br>
									The query shown in example 4 and shown below is used to create quick data visualization. The goal of this section is to show that you can pull a quick query and analyze data very fast with python and the pyscopg2 package. The plots below were created using the seaborn and matplotlib libraries. The set up for each example is to show the picture of the python code to create the plots, the plots, and my personal thoughts.
									<center>
									<span class="image fit">
									<img src="images/postgre_sql/viz.PNG" alt=""/>
									</span>
									</center>
									<br><br>
									
									<u>Example 1</u>
									<center>
									<span class="image fit">
									<img src="images/postgre_sql/viz1.1.PNG" alt=""/>
									<img src="images/postgre_sql/viz1.2.PNG" alt=""/>
									</span>
									</center>
									The plot was created using the matplotlib library and shows the sales of millions of dollars for all the varying stores each month. It appears that Berkeley makes the most sales while Nashville struggles to make equivalent sales. In March, August, and October there seems to be a boom in sales while the months between March and August there seems to be a slow period of sales. This can help prepare the stores to stock more up on the peak season and to wean down the stock in between the peak seasons. 
									<br><br>

									<u>Example 2</u>
									<center>
									<span class="image fit">
									<img src="images/postgre_sql/viz2.1.PNG" alt=""/>
									<img src="images/postgre_sql/viz2.2.PNG" alt=""/>
									</span>
									</center>
									The plot shown in example 2 was created using the seaborn library and represents all the sales stores by varying month. The left axis represents total sales in millions of dollars and you can see the same trend as example 1 where March, August, and October had the peak sales. Since example 2 stores followed the same trend the same information can be derived from example 1. The goal of this example is to show the use of a seaborn plot and the ease of use.
									<br><br>

									<u><strong>Conclusion</strong></u>
									<br>
									Running quick queries and data exploration can be done with the combination of python and psycopg2. By importing the pyscopg2 library and creating a connection with the SQL database allows the coder to work effectively and quickly. Using this method can also be useful in building data pipelines and validating that the data your pulling is being captured and correctly formatted.
								</p>

							</article>

							<!-- Data Wrangling -->
							<article id ="DataW">
								<button type="button" onclick="location.href='#work'"> Back to Project List</button>
								<h2> Writting the Report </h2>
							</article>

							<!-- Statistical Analysis -->
								<article id ="Stats">
									<button type="button" onclick="location.href='#work'"> Back to Project List</button>
									<br><br>
									<h2 class = "major"> <center>Democrats or Republicans.<br>Who had more difficulty<br> voting?</center> </h2>
									<p><small>By: Christian Lee, Ivy Chan, Jonathan Hodges, Dipika Kumar</small>
									<br><a href = "https://github.com/ejunlee/Portfolio/tree/main/Statistical_Analysis">Click for the Github Repo</a>
									</p>
									
									<p>
										<strong>1. Importance and Context</strong>
										<br>
										Voter engagement for the 2020 United States presidential election was at record levels, with more voters saying “it really matters” who wins the presidency than at any point over the last twenty years. At the same time, challenges such as the pandemic and social unrest led to half of the registered voters indicating it would be difficult to vote in the election. There has been a significant change since October 2018, shortly before that year’s midterm election, when 85% of registered voters said it would be easy to vote in the midterm elections. A better understanding of the various influencers of voter turnout is useful for your organization for party strategists and campaign managers.
										<br>
										This study will focus on the 2020 election and better understand the difficulty levels in voting between parties, which is one of many factors impacting voter turnout. Specifically, the goal of the analysis is to address the following research question:
										<center>Did Democratic voters or Republican voters experience more difficulty voting in the 2020 election? 
										</center>
										<br>
										As consultants we are here to answer this question in order to provide guidance and a foundation for your future research. This includes determining if voter difficulty is a major bellwether of turnout and, if so, further decomposing the factors that lead to these difficulty levels, such as registration, absentee versus in-person voting, long waits at polling places, or bad weather, which can be analyzed in the future. In addition, this analysis will allow us to identify if the difference in difficulty voting between Republicans vs. Democrats was statistically significant in the recent election. If the results are statistically significant, the reasons for difficulty in voting can be further assessed and mitigated.
										<br><br>
										<strong>2. Data and Methodology</strong>
										<br>
										The study utilized data from the 2020 Times Series Study conducted by the American National Election Studies (ANES). The Times Series Study interviewed 8280 individuals and comprised pre-election and post-election interviews from August 2020 through the end of December 2020. The sample we created from a subset of the ANES Times Series Study is limited in terms of generalizing to the US voter population across all demographic groups. This is due to the fact that we didn't leverage the weighting provided by ANES that is based on the US census.
										<br><br>
										Before answering the question of which political party had more difficulty voting, we need to operationalize the concepts, including who is a voter, their political affiliation, and the type of difficulty the individual had. Having this information provides context to exhibit who had more difficulty voting statistically. 
										<br><br>
										To classify a respondent as a voter, we look at those who have already registered to vote (at their current address, another address, or without an address) or are planning on registering to vote. As registering is a prerequisite for voting, we believe this variable is a strong indicator of being a voter. For V201008, values 1, 2, and 3 gave information about their registration address, while the other values did not give additional information. V201009 determined if voters were registered to vote, and value 1 gave applicable information for the study. 
										<br><br>
										We use the following fields for voter identification:
										<br><br>
										<div class="table-wrapper">
											<table>
												<thead>
													<tr>
														<th>Variable_Name</th>
														<th>Description</th>
														<th>Value</th>
													</tr>
												</thead>
												<tbody>
													<tr>
														<td>V201008</td>
														<td>PRE: WHERE IS R REGISTERED TO VOTE (PRE-ELECTION)</td>
														<td>1,2,3</td>
													</tr>
													<tr>
														<td>V201009</td>
														<td>PRE: WEB ONLY: IS R WITHOUT ADDRESS REGISTERED TO VOTE (PRE-ELECTION)</td>
														<td>1</td>
													</tr>
												</tbody>
											</table>
										</div>
											There are multiple ways to identify a respondent's respective party, for instance, voting behavior in past elections, voting in the primaries, the party they are currently registered to, etc. The pre-election self-identified affiliation variable was the best way to measure a respondent's political stance due to the quality and quantity of the data. Their political stance before and during the act of voting was taken into consideration. Values 1 and 2 correspond to the political party, while the other values did not give any more information.
										<br><br>
										We use the following field for party affiliation:
										<br><br>
										
										<div class="table-wrapper">
											<table>
												<thead>
													<tr>
														<th>Variable_Name</th>
														<th>Description</th>
														<th>Value</th>
													</tr>
												</thead>
												<tbody>
													<tr>
														<td>V201228</td>
														<td>PRE: PARTY ID: DOES R THINK OF SELF AS DEMOCRAT, REPUBLICAN, OR INDEPENDENT</td>
														<td>1,2</td>
													</tr>
												</tbody>
											</table>
										</div>
										How difficult it was for respondents to vote and the main reason respondents did not vote were used to determine the difficulty in voting. The combination of the two factors encompassed how hard it was for voters to cast their vote and why they found voting difficult. The values (2,3,4,5) of having difficulty voting were used in the study to determine which party had more difficulty for V202119. We utilized values that were not in the respondents control that induced difficulty in voting for V202123.
										<br><br>
										We use the following field for party affiliation:
										<br><br>

										<div class="table-wrapper">
											<table>
												<thead>
													<tr>
														<th>Variable_Name</th>
														<th>Description</th>
														<th>Value</th>
													</tr>
												</thead>
												<tbody>
													<tr>
														<td>V202119</td>
														<td>POST: HOW DIFFICULT WAS IT FOR R TO VOTE</td>
														<td>2, 3, 4, 5</td>
													</tr>
													<tr>
														<td>V202123</td>
														<td>POST: MAIN REASON R DID NOT VOTE</td>
														<td>9, 10, 11, 12, 13, 14, 15</td>
													</tr>
												</tbody>
											</table>
										</div>
										After assigning true or false values based on if it was difficult for party members to vote, we observed how many democrats and republicans had difficulty voting. 
										
										<span class="image fit">
										<img src="images/stats/viz1.PNG" alt=""/> 
										<figcaption><center>Difficulty Voting Democrats(D) vs Republicans(R)</center></figcaption>
										</span>
										

										Democrats had more true and false values, which aligned with the population of democrats being higher than republicans. However, we looked into the true and false cases as a percentage of the respective party population samples. The percentage difference between true and false was not notable between parties. Utilizing the party as a grouping variable and defining the response variable as proportional count of difficulties per group we can conduct some statistical tests. 
										<br><br>
										We evaluated various reputable hypothesis tests to determine which is best for answering our research question. After reviewing the assumptions that must be met for each test, we were able to narrow our choices down to the two-sample proportion test and the comparison version of the Wilcoxon rank sum test. As we evaluated difficulty as a binary true or false value instead of a scale of ordered categories, the data was determined to be more appropriately wrangled for the proportion test. Additionally, the Wilcoxon rank sum test is of lesser statistical power; therefore, we determined the proportion test was best suited for our analysis from these two test options. 
										<br><br>
										The proportional statistic assumptions were validated for proper use of the test statistic. The first assumption for the proportional two-group comparison test was independence and identical distributions (i.i.d). Independence can be assumed since random sampling occurred, and one sample's information cannot be inferred from other samples. However, the population of the samples changes from 8280 (pre-election interviews) to 7,782 (post-election interviews). There is a 7% decrease in the population size, which will not heavily affect the probability distribution. The following other assumptions are correct as the sample population follows a binomial distribution, and the data are simple random values from the population. 
										<br><br>
										While evaluating for practical significance, Cohen’s d is not well suited as it requires normality. For our binary data, we chose the Phi coefficient, which yielded a value of -0.031. The result indicates that there is virtually no relationship between political party and voter difficulty, meaning other factors drive difficulty.
										<br><br>
										Below is the accounting table summarizing the data wrangling after the exploratory data analysis (EDA) of the dataset.
										<br><br>
										<div class="table-wrapper">
											<table>
												<thead>
													<tr>
														<th>Cause</th>
														<th>Number of Samples Available for Analysis (after removal for cause)</th>
														<th>Removed Number Samples for cause</th>
													</tr>
												</thead>
												<tbody>
													<tr>
														<td>Start</td>
														<td>8280</td>
														<td>0</td>
													</tr>
													<tr>
														<td>Non-Voter</td>
														<td>7888</td>
														<td>392</td>
													</tr>
													<tr>
														<td>Independents (non-partisans) or no party affiliation provided</td>
														<td>5280</td>
														<td>2608</td>
													</tr>
												</tbody>
												<tfoot>
													<tr>
														<th colspan="3">
														<font size= "-1"><i>Note: For the response variable value that is not included in the selections, we assign a binary/boolean value to the record. Therefore, we do not have any missing or out-of-range response variable values. </i> </font>
		
														</th>
													</tr>
												</tfoot>
											</table>
											</div>

											<strong>3. Result</strong>
											<br>
											As we have two independent samples, Democratic voters and Republican voters, and difficulty being defined and organized as binary/boolean values, we derived the counts for total voters and the counts for voters with difficulty for each party. We use the proportion hypothesis test for binary data. 
											<br><br>
											<i><strong>Null Hypothesis</strong>: The proportion of Democrat voters with difficulty voting is equal to the proportion of Republican voters with difficulty voting.
											<br>
											H0: p1=p2, versus select one HA: p1≠p2 
											</i>
											<br><br>
											The proportion hypothesis test returns a p-value of 0.02847, which leads us to fail to reject the null hypothesis as it is not within the rejection region (< 0.025).The result is not statistically significant.
											<br>
											
											<span class = "image fit"> 
											<img src="images/stats/viz2.PNG"/>
											</span>
											
											<strong>4. Discussion</strong>
											While this is limited based on how Democrats and Republicans responded to ANES interviews, our study found evidence that voting difficulty does not have a strong relationship with the voter's political party. It is consistent with our findings that there is no significant difference in the Democrat and Republican populations we compared for voting difficulty. Additionally, we have shown that difficulty wasn’t experienced at a very high rate across either party, with just over 10% of Democrats and Republicans expressing this in their survey responses. 
											<br>
											Since the 2020 election had the highest turnout in United States history, it does not appear that difficulty had a significant role in preventing people from getting to the polls. Instead, it may make sense for future research to look at other predictors of voter turnout, such as education or socioeconomic status.

									</p>
									
									

								</article>
							
							<!-- Causal Effects-->
							<article id ="Causal">
								<button type="button" onclick="location.href='#work'"> Back to Project List</button>
								<h2> Currently In Progress</h2>

							</article>

							<!-- Graph Databasses -->
								<article id ="GraphD">
									<button type="button" onclick="location.href='#work'"> Back to Project List</button>
									<h2> Currently In Progress</h2>

								</article>

							<!-- Visual Dashboard-->
							<article id ="Viz">
								<button type="button" onclick="location.href='#work'"> Back to Project List</button>
								<br><br>

								<h2>Sales Review Dashboard</h2>
								<p>
								Goal of the Dashboard:
								<br>
								Is creating an interactive and influential dashboard that displays company latest sales data that can be viewed by the regional leads and peers. 
								The assumption is that viewers have used tableau before.
								<br><br>
								The dashboard will be composed of:
								<br>
								•	Total sales <br> 
								•	Sales per region <br>
								•	Sales per year<br>
								•	Sales, # of sales, # of customers for each region<br>
								•	Top selling categories per region<br>
								•	A section of the order details for each region for a deeper dive
								<br><br>
								Below is an image of the main dashboard. You are able to filter the year and region by clicking the button on the left panel. The banners, line plot, horizontal bar chart, and the order details will be updated by the filter buttons on the left panel.
								There are three buttons above the number of curstomers banner. From left to right, The grid button will expand the order details for a better view, the image button will download the dashboard as a picture, and the pdf button will download the file as a pdf.
								<span class="image fit">
									<img src="images/viz/sales_1.png" alt=""/> 
								</span>
								<br>
								The picture below is the expanded view of the order details. To go back to the main dashboard you will need to reclick the grid button on the upper right corner.
								<span class="image fit">
									<img src="images/viz/sales_2.png" alt=""/> 
								</span>
								Figma was used to create the template and the icons ar from noun projects.
								<br>
								Click the button below to see the dashboard
								</p> 
								<button type="button" onclick="location.href='https://public.tableau.com/app/profile/christian4714/viz/Sales_16684805253810/Main'">Link to dashboard
								</button>
								<hr>
								<h2>Game Sales Dashboard</h2>
								<p>Will update into an dashboard. Still in progress.</p>

								<!-- Embdeded Dashboard commented out <iframe seamless frameborder="0" src="https://public.tableau.com/views/1st_dashboard_made/Dashboard1?:embed=yes&:display_count=yes&:showVizHome=no" width = '650' height = '450'>
								</iframe> -->
								
								<button type="button" onclick="location.href='https://public.tableau.com/views/1st_dashboard_made/Dashboard1'">Link to dashboard
								</button>
								<hr>
								<h2>Dashboard Guidelines</h2>
								<p>My thoughts and personal belief to build dashboards can be found in the button below.</p>
								<button type="'button" onclick="location.href='#guidelines_viz'">Link to my Guideline</button>
							</article>
						
							<!-- Guidelines to Dashboard-->
						<article id = "guidelines_viz">
							<button type="button" onclick="location.href = '#Viz'">Back to Dashboards
							</button>
							<br><br>
							<h2>My personal belief in developing Visual Boards</h2>
							<p>
							When building this dashboard, I used 5 key principles to design the look and feel of the dashboard.
							<br><br>
							1.)	Gathering the Requirements
							<br>
							When building a dashboard its good to start off by understanding and stating the goal of the project/dashboard. Next is knowing who will be using the dashboard and design the interaction with the person analytical maturity. Through out the process you should be trying to have touch points with the users to curate the dashboard even further. 
							<br>
							Throughout the development you will consistently refine and reprioritize the business questions, discover and document insights, and determine the different plots and figures needed to effectively answer the question.
							<br><br>
							2.)	Create a Template
							<br>
							When creating a template use figures and plots that are relevant and do not leave room for fluff. Use blank text and boxes to figure the placement and design to your grid. Use varying size and positions to create hierarchy and look at the color scheme last.
							<br><br>
							3.)	Use Icons and Art to your Advantage
							<br>
							Want to use icons that not distracting, communicate its meaning and easy to recognize. Make sure the icons follow with the format and style of the dashboard, and this can be achieved with using the same color scheme. If the icons cannot fully descript an section, use concise labels to provide context.
							<br><br>
							4.)	Choose Colors that Matter
							<br><br>
							5.)	Be Specific with your Fonts
							<br>
							Stick to on legible font and no more than 4 different font sizes on the board. Be strategic with fonts colors, bolding, and use alignment correctly (Not everything has to be center aligned).
							</p>
						</article>

						<!-- Elements -->
							<article id="elements">
								<h2 class="major">Elements</h2>
								<!-- The section to the end of the headers are examples -->
								<section>
									<h3 class="major">Text</h3>
									<p>This is <b>bold</b> and this is <strong>strong</strong>. This is <i>italic</i> and this is <em>emphasized</em>.
									This is <sup>superscript</sup> text and this is <sub>subscript</sub> text.
									This is <u>underlined</u> and this is code: <code>for (;;) { ... }</code>. Finally, <a href="#">this is a link</a>.</p>
									<hr />
									<h2>Heading Level 2</h2>
									<h3>Heading Level 3</h3>
									<h4>Heading Level 4</h4>
									<h5>Heading Level 5</h5>
									<h6>Heading Level 6</h6>
									<hr />
									
									<pre><code>i = 0;

while (!deck.isInOrder()) {
    print 'Iteration ' + i;
    deck.shuffle();
    i++;
}

print 'It took ' + i + ' iterations to sort the deck.';</code></pre>
								</section>

								<section>
									<h3 class="major">Lists</h3>

									<h4>Unordered</h4>
									<ul>
										<li>Dolor pulvinar etiam.</li>
										<li>Sagittis adipiscing.</li>
										<li>Felis enim feugiat.</li>
									</ul>

									<h4>Alternate</h4>
									<ul class="alt">
										<li>Dolor pulvinar etiam.</li>
										<li>Sagittis adipiscing.</li>
										<li>Felis enim feugiat.</li>
									</ul>

									<h4>Ordered</h4>
									<ol>
										<li>Dolor pulvinar etiam.</li>
										<li>Etiam vel felis viverra.</li>
										<li>Felis enim feugiat.</li>
										<li>Dolor pulvinar etiam.</li>
										<li>Etiam vel felis lorem.</li>
										<li>Felis enim et feugiat.</li>
									</ol>
									<h4>Icons</h4>
									<ul class="icons">
										<li><a href="#" class="icon brands fa-github"><span class="label">Github</span></a></li>
									</ul>

									<h4>Actions</h4>
									<ul class="actions">
										<li><a href="#" class="button primary">Default</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
									<ul class="actions stacked">
										<li><a href="#" class="button primary">Default</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
								</section>

								<section>
									<h3 class="major">Table</h3>
									<h4>Default</h4>
									<div class="table-wrapper">
										<table>
											<thead>
												<tr>
													<th>Name</th>
													<th>Description</th>
													<th>Price</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td>Item One</td>
													<td>Ante turpis integer aliquet porttitor.</td>
													<td>29.99</td>
												</tr>
												<tr>
													<td>Item Two</td>
													<td>Vis ac commodo adipiscing arcu aliquet.</td>
													<td>19.99</td>
												</tr>
												<tr>
													<td>Item Three</td>
													<td> Morbi faucibus arcu accumsan lorem.</td>
													<td>29.99</td>
												</tr>
												<tr>
													<td>Item Four</td>
													<td>Vitae integer tempus condimentum.</td>
													<td>19.99</td>
												</tr>
												<tr>
													<td>Item Five</td>
													<td>Ante turpis integer aliquet porttitor.</td>
													<td>29.99</td>
												</tr>
											</tbody>
											<tfoot>
												<tr>
													<td colspan="2"></td>
													<td>100.00</td>
												</tr>
											</tfoot>
										</table>
									</div>

									<h4>Alternate</h4>
									<div class="table-wrapper">
										<table class="alt">
											<thead>
												<tr>
													<th>Name</th>
													<th>Description</th>
													<th>Price</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td>Item One</td>
													<td>Ante turpis integer aliquet porttitor.</td>
													<td>29.99</td>
												</tr>
												<tr>
													<td>Item Two</td>
													<td>Vis ac commodo adipiscing arcu aliquet.</td>
													<td>19.99</td>
												</tr>
												<tr>
													<td>Item Three</td>
													<td> Morbi faucibus arcu accumsan lorem.</td>
													<td>29.99</td>
												</tr>
												<tr>
													<td>Item Four</td>
													<td>Vitae integer tempus condimentum.</td>
													<td>19.99</td>
												</tr>
												<tr>
													<td>Item Five</td>
													<td>Ante turpis integer aliquet porttitor.</td>
													<td>29.99</td>
												</tr>
											</tbody>
											<tfoot>
												<tr>
													<td colspan="2"></td>
													<td>100.00</td>
												</tr>
											</tfoot>
										</table>
									</div>
								</section>

								<!-- Button Functionality for homepage-->
								<section>
									<h3 class="major">Buttons</h3>
									<ul class="actions">
										<li><a href="#" class="button primary">Primary</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
									<ul class="actions">
										<li><a href="#" class="button">Default</a></li>
										<li><a href="#" class="button small">Small</a></li>
									</ul>
									<ul class="actions">
										<li><a href="#" class="button primary icon solid fa-download">Icon</a></li>
										<li><a href="#" class="button icon solid fa-download">Icon</a></li>
									</ul>
									<ul class="actions">
										<li><span class="button primary disabled">Disabled</span></li>
										<li><span class="button disabled">Disabled</span></li>
									</ul>
								</section>

								<!-- Email Section -->
								<section>
									<h3 class="major">Form</h3>
									<form method="post" action="#">
										<div class="fields">
											<div class="field half">
												<label for="demo-name">Name</label>
												<input type="text" name="demo-name" id="demo-name" value="" placeholder="Jane Doe" />
											</div>
											<div class="field half">
												<label for="demo-email">Email</label>
												<input type="email" name="demo-email" id="demo-email" value="" placeholder="jane@untitled.tld" />
											</div>
											<div class="field">
												<label for="demo-category">Category</label>
												<select name="demo-category" id="demo-category">
													<option value="">-</option>
													<option value="1">Manufacturing</option>
													<option value="1">Shipping</option>
													<option value="1">Administration</option>
													<option value="1">Human Resources</option>
												</select>
											</div>
											<div class="field half">
												<input type="radio" id="demo-priority-low" name="demo-priority" checked>
												<label for="demo-priority-low">Low</label>
											</div>
											<div class="field half">
												<input type="radio" id="demo-priority-high" name="demo-priority">
												<label for="demo-priority-high">High</label>
											</div>
											<div class="field half">
												<input type="checkbox" id="demo-copy" name="demo-copy">
												<label for="demo-copy">Email me a copy</label>
											</div>
											<div class="field half">
												<input type="checkbox" id="demo-human" name="demo-human" checked>
												<label for="demo-human">Not a robot</label>
											</div>
											<div class="field">
												<label for="demo-message">Message</label>
												<textarea name="demo-message" id="demo-message" placeholder="Enter your message" rows="6"></textarea>
											</div>
										</div>
										<ul class="actions">
											<li><input type="submit" value="Send Message" class="primary" /></li>
											<li><input type="reset" value="Reset" /></li>
										</ul>
									</form>
								</section>

							</article>
							
					</div>

				<!-- Footer -->
					<footer id="footer">
						<p class="copyright">Thank you for checking out my portfolio.</p>
					</footer>

			</div>

		<!-- BG -->
			<div id="bg"></div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
